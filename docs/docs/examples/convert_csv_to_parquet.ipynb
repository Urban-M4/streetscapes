{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import duckdb\n",
    "\n",
    "from streetscapes import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert CSV files to parquet and merging them together\n",
    "\n",
    "The CSV files of the original Global Streetscapes dataset add up to 64GB in total. Moreover, data is split in several files which can make it a bit cumbersome to work with. Here, we convert the data to Parquet, which reduces file size and makes it easier to load and manipulate the data. \n",
    "\n",
    "Additionally, we combine columns from several sources into a single dataset that should serve most usecases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/simplemaps.csv\n",
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/perception.csv\n",
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/osm.csv\n",
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/places365.csv\n",
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/segmentation.csv\n",
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/contextual.csv\n",
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/metadata_common_attributes.csv\n",
      "/Users/clairedonnelly/Documents/Urban-M4/streetscapes-data/data/ghsl.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert all csvs in data dir to parquet \n",
    "for file in (conf.DATA_DIR / \"data\").glob(\"*.csv\"):\n",
    "    print(file)\n",
    "    duckdb.sql(f\"\"\"\n",
    "        COPY '{file}'\n",
    "        TO '{file.with_suffix(\".parquet\")}' \n",
    "        (FORMAT 'parquet', COMPRESSION 'zstd')\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_readable(csv_size)='13.09 GB', human_readable(parquet_size)='3.39 GB'\n",
      "reduction_factor=3.861462931301085\n"
     ]
    }
   ],
   "source": [
    "csv_size = sum(file.stat().st_size for file in (conf.DATA_DIR / \"data\").glob(\"*.csv\") if file.is_file())\n",
    "parquet_size = sum(file.stat().st_size for file in (conf.DATA_DIR / \"data\").glob(\"*.parquet\") if file.is_file() and not file.name==\"combined.parquet\")\n",
    "\n",
    "def human_readable(size):\n",
    "    \"\"\"Format byte size in human readable format\"\"\"\n",
    "    order_of_magnitude = size.bit_length() // 10  # Dividing by 10 for base-1024 magnitude\n",
    "    match order_of_magnitude:\n",
    "        case 3:\n",
    "            return f\"{size / 1024**3:.2f} GB\"\n",
    "        case 2:\n",
    "            return f\"{size / 1024**2:.2f} MB\"\n",
    "        case 1:\n",
    "            return f\"{size / 1024:.2f} KB\"\n",
    "        case _:\n",
    "            return f\"{size} bytes\"\n",
    "\n",
    "print(f\"{human_readable(csv_size)=}, {human_readable(parquet_size)=}\")\n",
    "\n",
    "reduction_factor = csv_size/parquet_size\n",
    "print(f\"{reduction_factor=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We may want to combine multiple csv files together into a single parquet file. If we use JOIN like above on the full table, we quickly run into memory issues. This is because `duckdb.sql(...)` creates an in-memory database to load the data and keep track of intermediate results. Alternatively, duckdb can create a persistent database on disk using `duckdb.connect('database_filename')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_readable(combined_size)='1.85 GB'\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "        \"contextual\",\n",
    "        \"metadata_common_attributes\",\n",
    "        \"segmentation\",\n",
    "        \"simplemaps\",\n",
    "        \"ghsl\",\n",
    "        \"perception\",\n",
    "        \"places365\",\n",
    "        \"osm\",\n",
    "    ]\n",
    "\n",
    "with duckdb.connect(\"duck.db\", config={'threads': 1}) as con:\n",
    "    # Load each dataset onto disk from the each file\n",
    "    for filename in files:\n",
    "        con.sql(f\"CREATE TABLE {filename} AS SELECT * FROM '{conf.DATA_DIR}/data/{filename}.parquet'\")\n",
    "    \n",
    "    # Perform the joins.\n",
    "    for i, filename in enumerate(files[:-1]):\n",
    "        # Join the tables one by one and store intermediate results in separate tables\n",
    "        j = i + 1\n",
    "        target = filename if i==0 else f\"step{i}\"\n",
    "        con.sql(f\"CREATE TABLE step{j} AS SELECT * FROM {target} JOIN {files[j]} USING (UUID, source, orig_id)\")     \n",
    "    \n",
    "    # Finally, we can export the joined table to a new parquet file\n",
    "    con.sql(f\"COPY step{j} TO '{conf.DATA_DIR}/data/streetscapes.parquet' (FORMAT 'parquet', COMPRESSION 'zstd')\")\n",
    "\n",
    "# Remove the database from our filesystem\n",
    "os.remove(\"duck.db\")\n",
    "\n",
    "# Show the combined file size:\n",
    "combined_size = (conf.DATA_DIR / \"data\" / \"streetscapes.parquet\").stat().st_size\n",
    "print(f\"{human_readable(combined_size)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────────┬───────────┬──────────────────┬────────────┬──────────────┬──────────────┐\n",
       "│                 uuid                 │  source   │     orig_id      │ road_width │ type_highway │     city     │\n",
       "│               varchar                │  varchar  │      int64       │  varchar   │   varchar    │   varchar    │\n",
       "├──────────────────────────────────────┼───────────┼──────────────────┼────────────┼──────────────┼──────────────┤\n",
       "│ bc5862a5-5e4c-4f74-bdd5-598e140dbb8f │ Mapillary │  941074783267368 │ NULL       │ drive        │ Bogotá       │\n",
       "│ 4d445c9a-03e2-4dda-a494-caf907ad1620 │ Mapillary │ 2822175224761380 │ 12.2       │ walk         │ Berlin       │\n",
       "│ 57713c58-62b2-465b-9df3-087b6d970603 │ Mapillary │  387731282398462 │ NULL       │ walk         │ Washington   │\n",
       "│ 5ce677fe-1f66-4a6e-a162-88ff5d6cd80a │ Mapillary │ 4331166880261832 │ NULL       │ drive        │ Kuala Lumpur │\n",
       "│ 54fb768e-2864-4ed0-a658-e72f7a66cbc0 │ Mapillary │  808249360075988 │ NULL       │ drive        │ Luxembourg   │\n",
       "│ 2eab1b65-fc24-4c04-a1cd-8053488d3363 │ Mapillary │  509451426846513 │ 1.5        │ walk         │ Quito        │\n",
       "│ f6e0af2e-9fd5-48cc-ae0c-4b7f93c2e59c │ Mapillary │  812250723021100 │ NULL       │ walk         │ San José     │\n",
       "│ 68be1ea7-17dd-43e8-8237-9d21420bf7f9 │ Mapillary │  882089209046201 │ NULL       │ drive        │ Chisinau     │\n",
       "│ 3a999761-c4e5-473e-91b9-8718a0e042ef │ Mapillary │  225155698973449 │ NULL       │ drive        │ Athens       │\n",
       "│ ee6cffdc-02fe-4f25-96d9-7de6e7efb9f2 │ Mapillary │  853232441931152 │ NULL       │ drive        │ Pretoria     │\n",
       "│                  ·                   │     ·     │         ·        │  ·         │   ·          │  ·           │\n",
       "│                  ·                   │     ·     │         ·        │  ·         │   ·          │  ·           │\n",
       "│                  ·                   │     ·     │         ·        │  ·         │   ·          │  ·           │\n",
       "│ ccbf8735-9390-485c-80ab-5738ad536af4 │ Mapillary │  289968889470878 │ NULL       │ drive        │ Lima         │\n",
       "│ 1628ad57-618f-459c-b8be-3c5c985d117c │ Mapillary │  314850844066578 │ NULL       │ walk         │ Stockholm    │\n",
       "│ ec4885da-9479-48a9-b535-209466639ab1 │ Mapillary │ 3893013857487720 │ NULL       │ drive        │ Rabat        │\n",
       "│ 6c323249-12f0-4f22-9cba-7255f6447bd0 │ Mapillary │  298363169013359 │ NULL       │ drive        │ Doha         │\n",
       "│ 3a143bf9-d699-4888-a514-4e6f986e9922 │ Mapillary │ 5431888820215523 │ NULL       │ drive        │ Dushanbe     │\n",
       "│ 623b8dea-0a22-4c2a-9e83-8e64b1b726f9 │ Mapillary │  827663171199611 │ NULL       │ drive        │ Berlin       │\n",
       "│ d358eee9-8029-4270-a4fb-00a30dd5618a │ Mapillary │ 1263166274113421 │ NULL       │ drive        │ Taipei       │\n",
       "│ 3b58b6cb-8df0-409b-87e4-ae7a6b3283fa │ Mapillary │ 1721547711372505 │ 1.5        │ walk         │ Riga         │\n",
       "│ 5b0fac8d-ff82-4bd3-a145-3d64c86ef1e4 │ Mapillary │  476410333436610 │ NULL       │ NULL         │ Kuala Lumpur │\n",
       "│ 412405a7-d286-4448-9274-471c6d691c30 │ Mapillary │  472018337394268 │ NULL       │ drive        │ Chisinau     │\n",
       "├──────────────────────────────────────┴───────────┴──────────────────┴────────────┴──────────────┴──────────────┤\n",
       "│ ? rows (>9999 rows, 20 shown)                                                                        6 columns │\n",
       "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's inspect the new file to see if the join has worked\n",
    "duckdb.sql(f\"SELECT * FROM '{conf.DATA_DIR}/data/combined.parquet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some usecases it might be more convenient to select certain columns from different files into a single table. This can be achieved in a similar manner to the previous example. Here, we create a dictionary with the file names and columns we want to select. We also need to specify a column that is common to all files to join on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary choosing files and columns\n",
    "selection = {\n",
    "    \"contextual\": ['UUID', 'source', 'orig_id'],\n",
    "    \"osm\": ['UUID', 'road_width', 'type_highway'],\n",
    "    \"simplemaps\": ['UUID', 'city'],\n",
    "    \"metadata_common_attributes\": ['UUID', 'lat', 'lon']\n",
    "}\n",
    "\n",
    "with duckdb.connect(\"duck.db\", config={'threads': 1}) as con:\n",
    "    # Load each dataset onto disk from the each file\n",
    "    for file, columns in selection.items():\n",
    "        col_str = ', '.join(columns) \n",
    "        con.sql(f\"CREATE TABLE {file} AS SELECT {col_str} FROM '{conf.DATA_DIR}/data/{file}.parquet'\")\n",
    "\n",
    "    # Perform the joins.\n",
    "    items = list(selection.items())\n",
    "    for i, (file, columns) in enumerate(items[:-1]):\n",
    "        # Join the tables one by one and store intermediate results in separate tables\n",
    "        j = i + 1\n",
    "        target = file if i==0 else f\"step{i}\"\n",
    "        next_file = items[j][0]\n",
    "        con.sql(f\"CREATE TABLE step{j} AS SELECT * FROM {target} JOIN {next_file} USING (UUID)\")     \n",
    "\n",
    "    # Finally, we can export the joined table to a new parquet file\n",
    "    con.sql(f\"COPY step{i} TO '{conf.DATA_DIR}/data/combined.parquet' (FORMAT 'parquet', COMPRESSION 'zstd')\")\n",
    "\n",
    "os.remove(\"duck.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────────────────────┬───────────┬──────────────────┬────────────┬──────────────┬──────────────┐\n",
       "│                 uuid                 │  source   │     orig_id      │ road_width │ type_highway │     city     │\n",
       "│               varchar                │  varchar  │      int64       │  varchar   │   varchar    │   varchar    │\n",
       "├──────────────────────────────────────┼───────────┼──────────────────┼────────────┼──────────────┼──────────────┤\n",
       "│ bc5862a5-5e4c-4f74-bdd5-598e140dbb8f │ Mapillary │  941074783267368 │ NULL       │ drive        │ Bogotá       │\n",
       "│ 4d445c9a-03e2-4dda-a494-caf907ad1620 │ Mapillary │ 2822175224761380 │ 12.2       │ walk         │ Berlin       │\n",
       "│ 57713c58-62b2-465b-9df3-087b6d970603 │ Mapillary │  387731282398462 │ NULL       │ walk         │ Washington   │\n",
       "│ 5ce677fe-1f66-4a6e-a162-88ff5d6cd80a │ Mapillary │ 4331166880261832 │ NULL       │ drive        │ Kuala Lumpur │\n",
       "│ 54fb768e-2864-4ed0-a658-e72f7a66cbc0 │ Mapillary │  808249360075988 │ NULL       │ drive        │ Luxembourg   │\n",
       "│ 2eab1b65-fc24-4c04-a1cd-8053488d3363 │ Mapillary │  509451426846513 │ 1.5        │ walk         │ Quito        │\n",
       "│ f6e0af2e-9fd5-48cc-ae0c-4b7f93c2e59c │ Mapillary │  812250723021100 │ NULL       │ walk         │ San José     │\n",
       "│ 68be1ea7-17dd-43e8-8237-9d21420bf7f9 │ Mapillary │  882089209046201 │ NULL       │ drive        │ Chisinau     │\n",
       "│ 3a999761-c4e5-473e-91b9-8718a0e042ef │ Mapillary │  225155698973449 │ NULL       │ drive        │ Athens       │\n",
       "│ ee6cffdc-02fe-4f25-96d9-7de6e7efb9f2 │ Mapillary │  853232441931152 │ NULL       │ drive        │ Pretoria     │\n",
       "│                  ·                   │     ·     │         ·        │  ·         │   ·          │  ·           │\n",
       "│                  ·                   │     ·     │         ·        │  ·         │   ·          │  ·           │\n",
       "│                  ·                   │     ·     │         ·        │  ·         │   ·          │  ·           │\n",
       "│ ccbf8735-9390-485c-80ab-5738ad536af4 │ Mapillary │  289968889470878 │ NULL       │ drive        │ Lima         │\n",
       "│ 1628ad57-618f-459c-b8be-3c5c985d117c │ Mapillary │  314850844066578 │ NULL       │ walk         │ Stockholm    │\n",
       "│ ec4885da-9479-48a9-b535-209466639ab1 │ Mapillary │ 3893013857487720 │ NULL       │ drive        │ Rabat        │\n",
       "│ 6c323249-12f0-4f22-9cba-7255f6447bd0 │ Mapillary │  298363169013359 │ NULL       │ drive        │ Doha         │\n",
       "│ 3a143bf9-d699-4888-a514-4e6f986e9922 │ Mapillary │ 5431888820215523 │ NULL       │ drive        │ Dushanbe     │\n",
       "│ 623b8dea-0a22-4c2a-9e83-8e64b1b726f9 │ Mapillary │  827663171199611 │ NULL       │ drive        │ Berlin       │\n",
       "│ d358eee9-8029-4270-a4fb-00a30dd5618a │ Mapillary │ 1263166274113421 │ NULL       │ drive        │ Taipei       │\n",
       "│ 3b58b6cb-8df0-409b-87e4-ae7a6b3283fa │ Mapillary │ 1721547711372505 │ 1.5        │ walk         │ Riga         │\n",
       "│ 5b0fac8d-ff82-4bd3-a145-3d64c86ef1e4 │ Mapillary │  476410333436610 │ NULL       │ NULL         │ Kuala Lumpur │\n",
       "│ 412405a7-d286-4448-9274-471c6d691c30 │ Mapillary │  472018337394268 │ NULL       │ drive        │ Chisinau     │\n",
       "├──────────────────────────────────────┴───────────┴──────────────────┴────────────┴──────────────┴──────────────┤\n",
       "│ ? rows (>9999 rows, 20 shown)                                                                        6 columns │\n",
       "└────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's inspect the new file to see if the join has worked\n",
    "duckdb.sql(f\"SELECT * FROM '{conf.DATA_DIR}/data/combined.parquet'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in touch with the developers of the original Open Streetscapes dataset to add these parquet files to the dataset on huggingface."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
